# ImageCaptioning

In this project we have a set of images with captions, and we create an algorithm that uses this data to describe a given image with a generated caption. 
To do this we make use of convolutional neural networks, as well as rcurrent neural networks (specifically an lstm).

## Python Libraries required
Standard python libraries such as numpy and matplotlib will be needed. Also, libraries and packages such as torch, torchvision, sys, PIL nltk, and OS will be needed. 
In addition, you will also need the COCO dataset, which can be fouund here: https://cocodataset.org/#home 

### Installation
To install any library, just use the pip install function, for example:
$ pip install Pillow

This will work for windows, mac and linux. For othe libraries, replace 'Pillow' with the name of the other library to be download.

### Author(s)

Ravinder Rai

### Acknowledgments
This project originates from the Computer Vision Nanodegree offered by Udacity. 
